# =============================================================
# InternAgent Environment Configuration
# LiteLLM + GitHub Copilot Setup
# =============================================================

# ------------------------------------------------------------------
# LiteLLM Proxy (primary entrypoint for all model calls)
# Run: litellm --model github_copilot/gpt-4o --port 4000
# InternAgent talks to LiteLLM as if it were the OpenAI API
# ------------------------------------------------------------------
OPENAI_API_KEY=litellm-proxy          # Any non-empty string works when using LiteLLM proxy
OPENAI_API_BASE_URL=http://localhost:4000  # LiteLLM proxy address

# ------------------------------------------------------------------
# GitHub Copilot credentials (used by LiteLLM to authenticate)
# Get your token from: https://github.com/settings/tokens
# Required scopes: copilot (or use a GitHub App token)
# ------------------------------------------------------------------
GITHUB_TOKEN=                         # Your GitHub personal access token or Copilot OAuth token

# ------------------------------------------------------------------
# Fallback / alternative LLM providers (optional)
# Uncomment and fill if you want LiteLLM to fall back to these
# ------------------------------------------------------------------
# ANTHROPIC_API_KEY=
# OPENROUTER_API_KEY=

# ------------------------------------------------------------------
# Search engine API keys (used for literature/web search)
# ------------------------------------------------------------------
GOOGLE_API_KEY=                       # Google Custom Search API key
S2_API_KEY=                           # Semantic Scholar API key (free at semanticscholar.org)
