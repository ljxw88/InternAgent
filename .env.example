# =============================================================
# InternAgent Environment Configuration
# LiteLLM + GitHub Models — Claude Sonnet 4.6
# =============================================================

# ------------------------------------------------------------------
# LiteLLM Proxy (primary entrypoint for all model calls)
# Run: litellm --config litellm_config.yaml --port 4000
# InternAgent talks to LiteLLM as if it were the OpenAI API.
# LiteLLM routes calls to Claude Sonnet 4.6 via GitHub Models.
# ------------------------------------------------------------------
OPENAI_API_KEY=litellm-proxy           # Must match master_key in litellm_config.yaml
OPENAI_API_BASE_URL=http://localhost:4000  # LiteLLM proxy address

# ------------------------------------------------------------------
# GitHub Models credentials (used by LiteLLM to authenticate)
# Get your token from: https://github.com/settings/tokens
# Required: classic token with no special scopes, or a fine-grained
# token — GitHub Models only requires a valid GitHub identity.
# ------------------------------------------------------------------
GITHUB_TOKEN=                          # Your GitHub personal access token

# ------------------------------------------------------------------
# Search engine API keys (used for literature/web search)
# ------------------------------------------------------------------
GOOGLE_API_KEY=                        # Google Custom Search API key
S2_API_KEY=                            # Semantic Scholar API key (free at semanticscholar.org)
