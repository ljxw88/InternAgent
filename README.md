# InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery
> *Autonomous Discovery Across All Sciences*
- **Papers**: [InternAgent 1.0](https://arxiv.org/abs/2505.16938) | [InternAgent 1.5](https://huggingface.co/papers/2602.08990)
- **Links**: [Website](https://discovery.intern-ai.org.cn) | [HuggingFace](https://huggingface.co/collections/InternScience/internagent)


## ğŸ”¥ News
ğŸ“Œ **Pinned**: Leveraging the general capabilities of InternAgent 1.5, **anyone can now submit their algorithm tasks for optimization by opening an [issue](https://github.com/InternScience/InternAgent/issues/new?template=task_submit.yml) in this repository.** We will **regularly update** the algorithm design results on this [website](https://internscience.github.io/InternAgent/). For other scientific discovery tasks, please visit [Intern-Discovery](https://discovery.intern-ai.org.cn/org/ailab/).

---

- **2026.2.14**: â¤ï¸â€ğŸ”¥â¤ï¸â€ğŸ”¥ We open-source **[MLEvolve](https://github.com/InternScience/MLEvolve)**, the core implementation of InternAgent's solution optimization subsystem for algorithm design tasks. As the **open-source method** to achieve **#1 on MLEBench**, MLEvolve demonstrates powerful capabilities in solution optimization within bounded hypothesis spaces. 

- **2026.2.12**: ğŸ”¥ ğŸ”¥ Leveraging the general capabilities of InternAgent 1.5, **anyone can now submit their algorithm tasks for optimization by opening an [issue](https://github.com/InternScience/InternAgent/issues/new?template=task_submit.yml) in this repository.** We will **regularly update** the algorithm design results on this [website](https://internscience.github.io/InternAgent/). For other scientific discovery tasks, please visit [Intern-Discovery](https://discovery.intern-ai.org.cn/org/ailab/).

- **2026.2.10**: ğŸ”¥ Official release of the [InternAgent 1.5 Technical Report](https://huggingface.co/papers/2602.08990). InternAgent 1.5 achieves leading performance on scientific reasoning benchmarks including **GAIA, HLE, GPQA, and FrontierScience**, and supports end-to-end autonomous scientific discovery tasks across **Physical, Biology, Earth, and Life Science domains**, enabling both algorithm discovery and empirical discovery (dry/wet-lab experiments).

- **2025.10.13**: InternAgent-1.0 code has been fully open-sourced, supporting end-to-end automation and autonomous evolution across 12 scientific research tasks.

- **2025.07.17**: The source code of InternAgent has been partially open-sourced. The complete version of InternAgent (covering 12 types of tasks for autonomous scientific research) will be open-sourced soon. This code repository can be used for full-cycle autonomous scientific research, ranging from hypothesis generation to automated experimental execution.

- **2025.07.10**: *NovelSeek* has been renamed to **InternAgent**. This change embodies our hopeful vision for autonomous scientific research framework, and we hope it will empower all researchers to achieve great scientific discoveries.

---

## ğŸ“– Overview

![InternAgent](assets/internagent_overall.png)

**InternAgent 1.5** is a unified autonomous system for end-to-end scientific discovery across both **Algorithm Discovery** and **Empirical Discovery**. Building on InternAgent 1.0, it organizes scientific inquiry into three coordinated subsystems: **Generation** (hypothesis construction via deep research), **Verification** (methodological evaluation via solution refinement), and **Evolution** (evidence-driven refinement via long-horizon memory).
![Benchmark](assets/benchmark.png)
InternAgent 1.5 achieves **leading performance** on scientific reasoning benchmarks (GAIA, HLE, GPQA, FrontierScience, SGI-bench) and demonstrates **sustained autonomous optimization** across extended discovery cycles. The system supports **algorithm discovery** (agent memory, reinforcement learning, test-time scaling, ...) and **empirical discovery** workflows (dry-lab simulations and wet-lab experimentation) across Physical, Biological, Earth, and Life Sciences.
![Capability](assets/capability.png)

---
## ğŸŒŸ Core Features

![Framework](assets/internagent_framework.png)

InternAgent 1.5 is built on three foundational subsystems that enable autonomous scientific discovery:

### ğŸ” Generation: Deep Research for Hypothesis Construction
- Autonomous literature analysis and knowledge synthesis across scientific domains
- Multi-source information integration from papers, code repositories, and domain-specific databases
- Structured hypothesis formulation grounded in existing scientific evidence

### âœ… Verification: Solution Refinement for Methodological Evaluation
- Systematic transformation of hypotheses into executable experimental protocols
- Automated code generation, debugging, and execution across computational and experimental environments
- Exception-guided intelligent error correction and iterative solution optimization

### ğŸ”„ Evolution: Long-Horizon Memory for Evidence-Driven Refinement
- Persistent memory architecture that accumulates knowledge across extended research cycles
- Cross-iteration learning from experimental outcomes and methodological feedback
- Adaptive optimization that continuously refines hypotheses and experimental designs

### ğŸ§© Three-Subsystem Coordination
- **Generation â†’ Verification â†’ Evolution** forms a complete discovery cycle
- Seamless integration of dry-lab (computational modeling) and wet-lab (physical experimentation) workflows
- Extensible architecture supporting diverse tasks across Algorithm Discovery and Empirical Discovery

**InternAgent 1.5** delivers end-to-end autonomous scientific discovery, enabling researchers to complete the full cycleâ€”from hypothesis generation to experimental validationâ€”across Physical, Biological, Earth, and Life Sciences.

---
## ğŸ”¬ Supported Research Tasks

**Scientific Algorithm Discovery**
- Suzukiâ€“Miyaura Reaction Yield Prediction
- Transcription Prediction for Perturbation Response
- Power Flow Estimation
- Time Series Forecasting
- Molecular Dynamics Simulation
- Enhancer Activity Prediction

**AI Algorithm Discovery**
- Test-Time Scaling for LLM Reasoning
- Long-Term Memory Management for Agents
- Self-Distillation for Mathematical Reasoning
- Test-Time Reinforcement Learning

**Empirical Discovery**
- Automated Climate Diagnostics
- Climate Downscaling Optimization
- Biological Evidence Synthesis for Target Discovery
- Hypothesis Generation and Target Prioritization
- Fluorescent Protein Engineering
- Automated Reaction Outcome Prediction
- Generative Scaffold Hopping
*And more...*

---

## ğŸ‰ Benchmark Results

### Results on Al Research Tasks

InternAgent consistently improves upon the baseline and outperforms Dolphin across all tasks, spanning AI and scientific domains.

#### Max Performance

| Task | Metric | Baseline | Dolphin | InternAgent |
|------|--------|----------|---------|-------------|
| AutoRYP | RÂ² â†‘ | 27.6 | 31.8 (+4.2) | **35.4 (+7.8)** |
| AutoMD | Forces-MAE â†“ | 0.158 | 0.152 | **0.148** |
| AutoPower | RMSE â†“ | 0.00473 | 0.00455 | **0.00426** |
| AutoTSF | MAE â†“ | 0.4382 | 0.4627 | **0.4331** |
| AutoTPPR | MSE â†“ | 0.197 | 0.173 | **0.146** |
| AutoEAP | HK-PCC â†‘ | 0.65 | 0.76 | **0.79** |
| AutoSenCls | Acc â†‘ | 91.0 | 92.5 (+1.5) | **93.5 (+2.5)** |
| Auto2DCls | Top-1 Acc â†‘ | 81.2 | 82.0 (+0.8) | **83.3 (+2.1)** |
| Auto3DCls | OA â†‘ | 91.0 | 93.9 (+2.9) | **95.5 (+4.5)** |
| Auto2DSeg | mIoU â†‘ | 78.8 | - | **81.0 (+2.2)** |
| AutoPCDet | mAP â†‘ | 65.0 | - | **65.9 (+0.9)** |
| AutoVLM | QA â†‘ | 67.1 | - | **67.6 (+0.5)** |

#### Average Performance

| Task | Metric | Baseline | Dolphin | InternAgent |
|------|--------|----------|---------|-------------|
| AutoRYP | RÂ² â†‘ | 27.6 | 31.3 (+3.7) | **33.5 (+5.9)** |
| AutoMD | Forces-MAE â†“ | 0.158 | 0.155 | **0.152** |
| AutoPower | RMSE â†“ | 0.00473 | 0.00459 | **0.00447** |
| AutoTSF | MAE â†“ | 0.4382 | - | **0.4346** |
| AutoTPPR | MSE â†“ | 0.197 | 0.179 | **0.170** |
| AutoEAP | HK-PCC â†‘ | 0.65 | 0.73 | **0.77** |
| AutoSenCls | Acc â†‘ | 91.0 | 91.8 (+0.8) | **92.5 (+1.5)** |
| Auto2DCls | Top-1 Acc â†‘ | 81.2 | 81.8 (+0.6) | **82.2 (+1.0)** |
| Auto3DCls | OA â†‘ | 91.0 | 92.0 (+1.0) | **93.4 (+2.4)** |
| Auto2DSeg | mIoU â†‘ | 78.8 | - | **80.1 (+1.3)** |
| AutoPCDet | mAP â†‘ | 65.0 | - | **65.7 (+0.7)** |
| AutoVLM | QA â†‘ | 67.1 | - | **67.6 (+0.5)** |

---

### ğŸ§ª GAIA, GPQA-Diamond, FrontierScience and HLE Benchmarks

InternAgent-1.5 achieved state-of-the-art results across multiple benchmarks.
### Humanity's Last Exam (HLE)

| Setting | Model | Math | Bio/Med | CS/AI | Physics | Human. | Chem. | Engineer. | Other | Avg. |
|---------|-------|------|---------|-------|---------|--------|-------|-----------|-------|------|
| **Text-Only** | Deepseek-R1 | 9.30 | 8.60 | 7.40 | 5.80 | 11.00 | 5.60 | 10.30 | 7.50 | 8.60 |
| | Gemini-3-pro-preview | 45.08 | 26.13 | 26.79 | 32.67 | 44.04 | **34.65** | **29.69** | 32.39 | 38.00 |
| | **InternAgent-1.5** | **48.96** | **30.63** | **29.46** | **34.16** | **44.56** | 30.69 | 28.13 | **37.50** | **40.87** |
| **All-Set** | o4-mini | 19.00 | 11.40 | 12.90 | 12.60 | 9.10 | 12.70 | 12.60 | 6.90 | 14.30 |
| | GPT-5 | 31.00 | 22.10 | 24.90 | 21.70 | 20.60 | 16.40 | 14.40 | 18.00 | 24.80 |
| | Gemini-3-pro-preview | 44.76 | 27.14 | 29.05 | 31.30 | **42.92** | **40.00** | **32.43** | 34.33 | 38.04 |
| | **InternAgent-1.5** | **48.09** | **30.36** | **30.71** | **33.04** | 42.47 | 34.55 | 30.63 | **38.63** | **40.00** |

---

### FrontierScience Benchmark

| Method | **Olympiad (avg N=20)** |  |  |  | **Research (avg N=30)** |  |  |  |
|--------|---------|---------|---------|---------|---------|---------|---------|---------|
|  | **Bio** | **Chem** | **Phy** | **All** | **Bio** | **Chem** | **Phy** | **All** |
| o4-mini | **47.00Â±14.90** | 65.00Â±6.40 | 53.40Â±4.50 | 57.40Â±3.30 | 9.67Â±5.47 | 8.17Â±4.37 | 0.83Â±2.27 | 6.20Â±2.54 |
| InternS1-235B | 17.00Â±12.69 | 52.88Â±4.05 | 50.40Â±3.88 | 48.05Â±2.84 | 4.50Â±4.35 | 11.00Â±3.74 | 2.67Â±3.35 | 6.06Â±2.30 |
| Mirothinker-v1.5-30B-A3B | 22.86Â±4.52 | 69.64Â±7.49 | 54.86Â±3.18 | 57.57Â±3.66 | 8.17Â±6.39 | 8.50Â±6.21 | 5.83Â±4.10 | 7.50Â±3.77 |
| DeepSeek-V3.2-Thinking | 26.50Â±7.26 | 72.25Â±3.25 | 66.30Â±2.63 | 64.70Â±2.41 | 2.50Â±3.10 | 16.33Â±4.64 | 1.40Â±2.70 | 6.84Â±1.88 |
| Qwen3-235B-A22B-Thinking | 24.00Â±9.17 | 61.13Â±6.05 | 57.10Â±4.79 | 55.40Â±3.68 | 10.17Â±5.08 | 10.00Â±6.32 | 1.58Â±2.41 | 7.34Â±3.37 |
| Qwen3-30B-A3B-Thinking | 13.50Â±9.10 | 47.25Â±4.47 | 42.70Â±3.65 | 41.60Â±2.94 | 1.50Â±2.93 | 2.00Â±3.32 | 0.70Â±1.79 | 1.41Â±1.52 |
| **InternAgent-1.5** | 46.00Â±8.00 | **85.50Â±3.67** | **76.80Â±2.99** | **77.20Â±3.06** | **10.33Â±4.64** | **22.00Â±6.00** | **3.67Â±2.87** | **12.00Â±2.49** |

---

### GPQA-Diamond Benchmark

| Agent | Bio | Chem | Phys | Avg. |
|-------|-----|------|------|------|
| **Base Models** |  |  |  |  |
| Qwen-3-8B | - | - | - | 44.44 |
| Qwen3-32B | - | - | - | 49.49 |
| Qwen3-235B | - | - | - | 47.47 |
| Intern-S1 | **89.47** | 59.49 | 93.02 | 78.26 |
| Deepseek-R1 | 63.16 | 76.34 | 91.86 | 82.32 |
| o4-mini | 78.95 | 63.44 | 94.19 | 78.28 |
| GPT-5 | 84.21 | 76.34 | 95.35 | 85.35 |
| **React Model with Tools** |  |  |  |  |
| WebShaper | 47.37 | 52.69 | 81.40 | 64.65 |
| MiroThinker | 84.21 | 75.27 | 95.35 | 84.85 |
| Tongyi DR | 78.95 | 67.74 | 95.35 | 80.30 |
| **InternAgent-1.5** | 84.21 | **79.57** | **96.51** | **87.37** |

---
## ğŸš€ğŸš€ Getting Started with InternAgent 1.5

### Algorithm Discovery Tasks
For **algorithm discovery tasks** such as Reinforcement Learning, Test-time Scaling, Agent Memory... we currently support access to InternAgent 1.5 by **submitting an issue or pull request in this repository**. Please describe your optimization task, and we will regularly update the algorithm design results.

### Empirical Discovery Tasks
For **empirical discovery tasks** including computational modeling, dry-lab simulations, and wet-lab experimentation across Physical, Biological, Earth, and Life Sciences, please visit **[Intern-Discovery](https://discovery.intern-ai.org.cn/org/ailab/)**.

***Stay tuned for more updates as we expand access and capabilities!***

## ğŸš€ Getting Started with InternAgent 1.0

### Installation

```bash
conda create -n InternAgent python=3.11
conda activate InternAgent

# Install PyPI requirements
pip install -r requirements.txt

# Install aider
python -m pip install -U --upgrade-strategy only-if-needed aider-chat
```

### Set Your API Key

Rename `.env.example` to `.env` and fill in your API keys:

```bash
mv .env.example .env
```

### Start Your Research Project

```bash
./scripts/run_pipeline.sh
```

**Configuration Tips:**
- Modify `configs/config.yaml` to customize your research project
- Results will be saved in the `results/` directory
- Check logs in the `logs/` directory
- To skip idea generation, refer to `scripts/run_skip-idea.sh`
- Visualize idea evolution using `internagent/vis_tree.py`

### About Research Tasks

We provide the tasks mentioned in our technical report as examples. Each task has different training environments and datasets. Please refer to the code in each task's folder for configuration details.

---

## ğŸ“ Citation

```bibtex
@article{feng2026internagent,
  title={InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery},
  author={Shiyang Feng and Runmin Ma and Xiangchao Yan and Yue Fan and Yusong Hu and Songtao Huang and Shuaiyu Zhang and Zongsheng Cao and Tianshuo Peng and Jiakang Yuan and Zijie Guo and Zhijie Zhong and Shangheng Du and Weida Wang and Jinxin Shi and Yuhao Zhou and Xiaohan He and Zhiyin Yu and Fangchen Yu and Bihao Zhan and Qihao Zheng and Jiamin Wu and Mianxin Liu and Chi Zhang and Shaowei Hou and Shuya Li and Yankai Jiang and Wenjie Lou and Lilong Wang and Zifu Wang and Jiong Wang and Wanghan Xu and Yue Deng and Dongrui Liu and Yiheng Wang and Wenlong Zhang and Fenghua Ling and Shufei Zhang and Xiaosong Wang and Shuangjia Zheng and Xun Huang and Siqi Sun and Shuyue Hu and Peng Ye and Chunfeng Song and Bin Wang and Conghui He and Yihao Liu and Xin Li and Qibin Hou and Tao Chen and Xiangyu Yue and Bin Wang and Liang He and Dahua Lin and Bowen Zhou and Bo Zhang and Lei Bai},
  journal={arXiv preprint arXiv:2602.08990},
  year={2026}
}
```

```bibtex
@article{team2025internagent,
  title={InternAgent: When Agent Becomes the Scientist--Building Closed-Loop System from Hypothesis to Verification},
  author={Team, InternAgent and Zhang, Bo and Feng, Shiyang and Yan, Xiangchao and Yuan, Jiakang and Ma, Runmin and Hu, Yusong and Yu, Zhiyin and He, Xiaohan and Huang, Songtao and others},
  journal={arXiv e-prints},
  pages={arXiv--2505},
  year={2025}
}
```

```bibtex
@article{hu2025flowsearch,
  title={FlowSearch: Advancing deep research with dynamic structured knowledge flow},
  author={Yusong Hu and Runmin Ma and Yue Fan and Jinxin Shi and Zongsheng Cao and Yuhao Zhou and Jiakang Yuan and Xiangchao Yan and Wenlong Zhang and Lei Bai and Bo Zhang},
  journal={arXiv preprint arXiv:2510.08521},
  year={2025}
}
```

```bibtex
@article{du2025automlgen,
  title={AutoMLGen: Navigating Fine-Grained Optimization for Coding Agents},
  author={Shangheng Du and Xiangchao Yan and Dengyang Jiang and Jiakang Yuan and Yusong Hu and Xin Li and Liang He and Bo Zhang and Lei Bai},
  journal={arXiv preprint arXiv:2510.08521},
  year={2025}
}
```


## ğŸ¤– Running with LiteLLM + GitHub Copilot

This fork is pre-configured to use **LiteLLM** as a local proxy, routing all InternAgent LLM calls through **GitHub Copilot** models (gpt-4o, o3-mini, etc.) â€” no OpenAI API key required.

### Prerequisites

- A GitHub account with an active **GitHub Copilot** subscription
- - A GitHub personal access token with `copilot` scope
 
  - ### Setup
 
  - **1. Install dependencies**
  - ```bash
    conda create -n InternAgent python=3.11
    conda activate InternAgent
    pip install -r requirements.txt
    python -m pip install -U --upgrade-strategy only-if-needed aider-chat
    ```

    **2. Configure environment**
    ```bash
    cp .env.example .env
    # Edit .env and set your GITHUB_TOKEN
    ```

    **3. Start the LiteLLM proxy** (in a separate terminal)
    ```bash
    # Option A: Simple one-liner (uses gpt-4o via Copilot)
    litellm --model github_copilot/gpt-4o --port 4000

    # Option B: Use the full config file (recommended â€” includes fallbacks, retry logic)
    litellm --config litellm_config.yaml --port 4000
    ```

    **4. Run InternAgent**
    ```bash
    ./scripts/run_pipeline.sh
    ```

    ### How It Works

    ```
    InternAgent agents
           â”‚
           â–¼ (OpenAI-compatible API calls to localhost:4000)
      LiteLLM proxy
           â”‚
           â–¼ (authenticated with GITHUB_TOKEN)
    GitHub Copilot API
           â”‚
           â–¼
      gpt-4o / o3-mini
    ```

    InternAgent's `openai` provider is pointed at `http://localhost:4000` (set via `OPENAI_API_BASE_URL` in `.env`). LiteLLM translates the calls and forwards them to GitHub Copilot.

    ### Switching Models

    Edit `litellm_config.yaml` or use the CLI flag to switch between Copilot-available models:

    | Model | LiteLLM flag |
    |---|---|
    | GPT-4o | `--model github_copilot/gpt-4o` |
    | o3-mini | `--model github_copilot/o3-mini` |
    | Claude 3.5 Sonnet | `--model github_copilot/claude-3.5-sonnet` |

    Then update `model_name` in `config/config.yaml` to match.
