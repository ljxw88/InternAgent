# InternAgent Configuration
# Reconfigured for LiteLLM + GitHub Models
# Primary model: Claude Sonnet 4.6 (claude-sonnet-4-5)
#
# HOW IT WORKS:
#   InternAgent calls the "openai" provider, which is pointed at a local
#   LiteLLM proxy (http://localhost:4000). LiteLLM proxies all calls to
#   GitHub Models using your GITHUB_TOKEN.
#
# QUICK START:
#   1. Set GITHUB_TOKEN in your .env file
#   2. Start LiteLLM proxy:
#        litellm --config litellm_config.yaml --port 4000
#   3. Run InternAgent:
#        ./scripts/run_pipeline.sh

# System Version
version: "1.0.0"

# Model Providers Configuration
models:
  # Default provider - points to LiteLLM proxy acting as OpenAI-compatible API
    default_provider: "openai"

      # OpenAI-compatible config — backed by LiteLLM proxy → GitHub Models → Claude Sonnet 4.6
        # OPENAI_API_BASE_URL and OPENAI_API_KEY are set via .env
          openai:
              model_name: "claude-sonnet-4-5"    # Must match model_name alias in litellm_config.yaml
                  api_key: ""                         # Set via OPENAI_API_KEY env var (any string for proxy)
                      max_tokens: 4096
                          temperature: 0.7

                          # Agent Configuration
                          agents:
                            # Idea Generation Agent
                              generation:
                                  model_provider: "default"
                                      generation_count: 15
                                          creativity: 0.7
                                              do_survey: true
                                                  temperature: 0.9

                                                    # Survey Agent (for literature search)
                                                      survey:
                                                          model_provider: "default"
                                                              max_papers: 50

                                                                # Reflection Agent (for critique and analysis)
                                                                  reflection:
                                                                      model_provider: "default"

                                                                        # Evolution Agent (for idea evolution)
                                                                          evolution:
                                                                              model_provider: "default"
                                                                                  creativity_level: 0.6
                                                                                      temperature: 0.8
                                                                                          evolution_count: 3

                                                                                            # Method Development Agent — uses Claude Sonnet 4.6 via LiteLLM
                                                                                              method_development:
                                                                                                  model_provider: "openai"
                                                                                                      model_name: "claude-sonnet-4-5"
                                                                                                      
                                                                                                        # Refinement Agent — uses Claude Sonnet 4.6 via LiteLLM
                                                                                                          refinement:
                                                                                                              model_provider: "openai"
                                                                                                                  model_name: "claude-sonnet-4-5"
                                                                                                                  
                                                                                                                    # Ranking Agent (for idea scoring)
                                                                                                                      ranking:
                                                                                                                          model_provider: "default"
                                                                                                                              criteria:
                                                                                                                                    novelty: 0.3
                                                                                                                                          feasibility: 0.4
                                                                                                                                                impact: 0.2
                                                                                                                                                      clarity: 0.1
                                                                                                                                                      
                                                                                                                                                        # Scholar Agent (for literature search and relevance)
                                                                                                                                                          scholar:
                                                                                                                                                              model_provider: "default"
                                                                                                                                                                  search_depth: "moderate"
                                                                                                                                                                      max_papers: 10
                                                                                                                                                                          temperature: 0.6
                                                                                                                                                                          
                                                                                                                                                                          # Workflow Configuration
                                                                                                                                                                          workflow:
                                                                                                                                                                            max_iterations: 4
                                                                                                                                                                              top_ideas_count: 5
                                                                                                                                                                                top_ideas_evo: true
                                                                                                                                                                                  max_concurrent_tasks: 5
                                                                                                                                                                                  
                                                                                                                                                                                  # Memory/Storage Configuration
                                                                                                                                                                                  memory:
                                                                                                                                                                                    backend: "file_system"               # Options: file_system, in_memory
                                                                                                                                                                                      file_dir: "results"
                                                                                                                                                                                      
                                                                                                                                                                                      # External Tools Configuration
                                                                                                                                                                                      tools:
                                                                                                                                                                                        # Web Search
                                                                                                                                                                                          web_search:
                                                                                                                                                                                              enabled: true
                                                                                                                                                                                                  provider: "google"
                                                                                                                                                                                                      api_key: ""                         # Set via GOOGLE_API_KEY env var
                                                                                                                                                                                                          max_results: 5
                                                                                                                                                                                                          
                                                                                                                                                                                                            # Literature Search
                                                                                                                                                                                                              literature_search:
                                                                                                                                                                                                                  semantic_scholar_key: ""            # Set via S2_API_KEY env var
                                                                                                                                                                                                                      max_results: 10
                                                                                                                                                                                                                      
                                                                                                                                                                                                                      # Logging Configuration
                                                                                                                                                                                                                      logging:
                                                                                                                                                                                                                        level: "INFO"                         # DEBUG, INFO, WARNING, ERROR
                                                                                                                                                                                                                          file: "logs/intern_agent.log"
